{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c8b1e6c-d65c-48f6-b77c-850d5f3b6c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ FAISS is installed correctly!\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "print(\"✅ FAISS is installed correctly!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "318f4be2-0f37-47af-bc8b-8074ca8f1062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>year</th>\n",
       "      <th>genre_list</th>\n",
       "      <th>combined_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>415.0</td>\n",
       "      <td>toy story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "      <td>1995</td>\n",
       "      <td>['Adventure', 'Animation', 'Children', 'Comedy...</td>\n",
       "      <td>toy story (1995) Adventure|Animation|Children|...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>191.0</td>\n",
       "      <td>jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "      <td>1995</td>\n",
       "      <td>['Adventure', 'Children', 'Fantasy']</td>\n",
       "      <td>jumanji (1995) Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>941.0</td>\n",
       "      <td>grumpier old men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "      <td>1995</td>\n",
       "      <td>['Comedy', 'Romance']</td>\n",
       "      <td>grumpier old men (1995) Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3313.0</td>\n",
       "      <td>waiting to exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "      <td>1995</td>\n",
       "      <td>['Comedy', 'Drama', 'Romance']</td>\n",
       "      <td>waiting to exhale (1995) Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>942.0</td>\n",
       "      <td>father of the bride part ii (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>1995</td>\n",
       "      <td>['Comedy']</td>\n",
       "      <td>father of the bride part ii (1995) Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0    415.0                    toy story (1995)   \n",
       "1    191.0                      jumanji (1995)   \n",
       "2    941.0             grumpier old men (1995)   \n",
       "3   3313.0            waiting to exhale (1995)   \n",
       "4    942.0  father of the bride part ii (1995)   \n",
       "\n",
       "                                        genres  year  \\\n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  1995   \n",
       "1                   Adventure|Children|Fantasy  1995   \n",
       "2                               Comedy|Romance  1995   \n",
       "3                         Comedy|Drama|Romance  1995   \n",
       "4                                       Comedy  1995   \n",
       "\n",
       "                                          genre_list  \\\n",
       "0  ['Adventure', 'Animation', 'Children', 'Comedy...   \n",
       "1               ['Adventure', 'Children', 'Fantasy']   \n",
       "2                              ['Comedy', 'Romance']   \n",
       "3                     ['Comedy', 'Drama', 'Romance']   \n",
       "4                                         ['Comedy']   \n",
       "\n",
       "                                   combined_features  \n",
       "0  toy story (1995) Adventure|Animation|Children|...  \n",
       "1          jumanji (1995) Adventure|Children|Fantasy  \n",
       "2             grumpier old men (1995) Comedy|Romance  \n",
       "3      waiting to exhale (1995) Comedy|Drama|Romance  \n",
       "4          father of the bride part ii (1995) Comedy  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# Load Datasets\n",
    "movies = pd.read_csv('../../cleaned_remapped_movies.csv')\n",
    "ratings = pd.read_csv('../../cleaned_remapped_ratings.csv')\n",
    "display(movies.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d0602aa-ad03-429f-af26-ccd35581f94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Matrix shape: (87382, 42527)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Fit and transform the combined features\n",
    "tfidf_matrix = tfidf.fit_transform(movies['combined_features'])\n",
    "\n",
    "# Check the shape of the matrix\n",
    "print(\"TF-IDF Matrix shape:\", tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0f4b655-f27b-458c-8e8a-c73e018c2ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "print(faiss.__version__)  # Check FAISS version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "896099b2-a037-4a13-9bdb-bb3e1ba74eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "\n",
    "# class StreamToLogger:\n",
    "#     def __init__(self, stream):\n",
    "#         self.stream = stream\n",
    "\n",
    "#     def write(self, message):\n",
    "#         if message.strip():\n",
    "#             print(message)  # Print message explicitly\n",
    "\n",
    "#     def flush(self):\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5705956c-84f2-48d0-af81-875ed9d072e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ :::::::: FAISS is using 8 threads.\n",
      ":::::: Found valid subvector size 1 .......\n",
      ":::::: Starting FAISS training 1 .......\n",
      ":::::: Starting FAISS training 2 .......\n",
      ":::::: Starting FAISS training 3 .......\n",
      ":::::: Starting FAISS training 4 .......\n",
      ":::::: Starting FAISS training 5 .......\n",
      ":::::: Starting FAISS training 5 A .......\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import sys\n",
    "\n",
    "# FAISS Training Code\n",
    "'''\n",
    "Step 1: Find a Valid SUB_VECTOR_SIZE\n",
    "Step 2: Initialize FAISS Index\n",
    "Step 3: Train FAISS on a Random Subset\n",
    "Step 4: Add Vectors in Batches\n",
    "Step 5: Move FAISS Index to CPU & Save\n",
    "\n",
    "'''\n",
    "\n",
    "import faiss\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "BATCH_SIZE = 5000\n",
    "NUM_CLUSTERS = 1800\n",
    "PQ_BITS = 8\n",
    "\n",
    "\n",
    "faiss.omp_set_num_threads(8)  # Force FAISS to use all 8 CPUs\n",
    "print(f\"✅ :::::::: FAISS is using {faiss.omp_get_max_threads()} threads.\")\n",
    "\n",
    "# Load dataset dimensions\n",
    "VECTOR_DIM = tfidf_matrix.shape[1]\n",
    "\n",
    "def find_valid_subvector_size(vector_dim):\n",
    "    # List of FAISS-supported subvector sizes\n",
    "    valid_sizes = [64, 56, 48, 40, 32, 24, 16, 12, 8, 4, 3, 2, 1]\n",
    "\n",
    "    # Find the largest valid subvector size that evenly divides `vector_dim`\n",
    "    for m in valid_sizes:\n",
    "        if vector_dim % m == 0:\n",
    "            return m\n",
    "    return None\n",
    "\n",
    "SUB_VECTOR_SIZE = find_valid_subvector_size(VECTOR_DIM)\n",
    "print(f\":::::: Found valid subvector size {SUB_VECTOR_SIZE} .......\")\n",
    "\n",
    "if SUB_VECTOR_SIZE is None:\n",
    "    raise ValueError(f\"No valid `SUB_VECTOR_SIZE` found for VECTOR_DIM = {VECTOR_DIM}.\")\n",
    "\n",
    "\n",
    "print(\":::::: Starting FAISS training 1 .......\")\n",
    "\n",
    "\n",
    "# Initialize FAISS GPU resources\n",
    "res = faiss.StandardGpuResources()\n",
    "\n",
    "# Set 1GB GPU memory for FAISS operations\n",
    "res.setTempMemory(1 * 1024 * 1024 * 1024)\n",
    "\n",
    "print(\":::::: Starting FAISS training 2 .......\")\n",
    "quantizer = faiss.IndexFlatIP(VECTOR_DIM)\n",
    "print(\":::::: Starting FAISS training 3 .......\")\n",
    "index = faiss.IndexIVFPQ(quantizer, VECTOR_DIM, NUM_CLUSTERS, SUB_VECTOR_SIZE, PQ_BITS)\n",
    "print(\":::::: Starting FAISS training 4 .......\")\n",
    "\n",
    "\n",
    "print(\":::::: Starting FAISS training 5 .......\")\n",
    "\n",
    "\n",
    "\n",
    "# Train on 80,000 samples (FAISS best practice)\n",
    "num_train_samples = min(60000, tfidf_matrix.shape[0])\n",
    "random_indices = np.random.choice(tfidf_matrix.shape[0], num_train_samples, replace=False)\n",
    "train_data = tfidf_matrix[random_indices].toarray().astype(np.float32)\n",
    "\n",
    "\n",
    "\n",
    "# Set verbose output for training\n",
    "sys.stdout.flush()  # Force logs to appear in the \n",
    "# sys.stdout = StreamToLogger(sys.stdout)  # Redirect FAISS logs\n",
    "faiss.cvar.indexIVF_stats.reset()  # Reset FAISS internal stats\n",
    "faiss.cvar.indexIVF_stats.verbose = True  # Enable verbose output\n",
    "\n",
    "\n",
    "# ✅ Initialize the FAISS Index on CPU\n",
    "index_cpu = faiss.IndexIVFPQ(quantizer, VECTOR_DIM, NUM_CLUSTERS, SUB_VECTOR_SIZE, PQ_BITS)\n",
    "print(\":::::: Starting FAISS training 5 A .......\")\n",
    "start_time = time.time()\n",
    "index_cpu.train(train_data)  # Train on CPU\n",
    "end_time = time.time()\n",
    "print(\"✅ :::::: FAISS training completed!\")\n",
    "print(f\"✅ FAISS training completed in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "'''\n",
    "# Use FAISS FP16 Precision to Reduce Memory Usage\n",
    "# Reduces memory usage by 50%, enabling more efficient training.\n",
    "'''\n",
    "gpu_options = faiss.GpuMultipleClonerOptions()\n",
    "gpu_options.useFloat16 = True  # Enable FP16\n",
    "\n",
    "# Move FAISS index to GPU with allocated resources\n",
    "gpu_index = faiss.index_cpu_to_gpu(res, 0, index_cpu, gpu_options)\n",
    "\n",
    "print(\"✅ FAISS GPU memory allocated and index moved to GPU.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Train on 80,000 samples (FAISS best practice)\n",
    "# num_train_samples = min(80000, tfidf_matrix.shape[0])\n",
    "# random_indices = np.random.choice(tfidf_matrix.shape[0], num_train_samples, replace=False)\n",
    "# train_data = tfidf_matrix[random_indices].toarray().astype(np.float32)\n",
    "\n",
    "print(\":::::: Starting FAISS training 6 .......\")\n",
    "\n",
    "'''\n",
    "# Memory-inefficient way to train 80K samples\n",
    "gpu_index.train(train_data)\n",
    "'''\n",
    "\n",
    "\n",
    "# for i in range(num_iterations):\n",
    "#     start_idx = i * batch_size\n",
    "#     end_idx = (i + 1) * batch_train_size if i < num_iterations - 1 else train_data.shape[0]\n",
    "    \n",
    "#     batch_train_data = train_data[start_idx:end_idx]  # Slice a new batch of training data\n",
    "#     print(f\"🚀 Training iteration {i+1}/{num_iterations} on {batch_train_data.shape[0]} samples...\")\n",
    "    \n",
    "#     index_cpu.train(batch_train_data)\n",
    "\n",
    "\n",
    "print(\":::::: Starting FAISS training 7 .......\")\n",
    "\n",
    "# Add vectors in large batches\n",
    "for start in range(0, tfidf_matrix.shape[0], BATCH_SIZE):\n",
    "    print(f\"     :::::: Start ==> {start}\")\n",
    "    end = min(start + BATCH_SIZE, tfidf_matrix.shape[0])\n",
    "    batch_data = tfidf_matrix[start:end].toarray().astype(np.float32)\n",
    "    gpu_index.add(batch_data)\n",
    "\n",
    "# ✅ Save trained FAISS index\n",
    "final_index = faiss.index_gpu_to_cpu(gpu_index)\n",
    "faiss.write_index(final_index, \"../../faiss_gpu_index60k-1024.bin\")\n",
    "\n",
    "print(\"✅ FAISS model saved as faiss_gpu_index60k-1800.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbff9805-d5b2-4a21-9a45-5490c4d28079",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
