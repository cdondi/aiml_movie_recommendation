{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "2905681a-7681-4553-b2e1-14aeef7f56e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings Shape: (31842705, 4)\n",
      "Movies Shape: (87382, 6)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Load cleaned ratings data\n",
    "ratings = pd.read_csv('../data/cleaned_remapped_ratings.csv')\n",
    "movies = pd.read_csv('../data/cleaned_remapped_movies.csv')\n",
    "\n",
    "print(\"Ratings Shape:\", ratings.shape)\n",
    "print(\"Movies Shape:\", movies.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "87c7937c-4e52-4f0a-bac4-3ffd2d283f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200948, 31961)\n"
     ]
    }
   ],
   "source": [
    "# Generate the User-Item Interaction Matrix\n",
    "\n",
    "# Create a sparse user-item interaction matrix\n",
    "user_movie_matrix = csr_matrix(\n",
    "    (ratings['rating'], (ratings['userId'] - 1, ratings['movieId'] - ratings['movieId'].min()))\n",
    ")\n",
    "print(user_movie_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "b4ccc73c-20d9-4d4f-bf66-54ebee8ab29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "::::::::::: Movie factors shape =>  (31961, 50)\n",
      "::::::::::: User factors shape =>  (200948, 50)\n",
      "::::::::::: Movie indices length =>  87382\n",
      "Saved remapped movies indices !!!\n",
      ":::::: PKL files saved !!!\n"
     ]
    }
   ],
   "source": [
    "# Apply Truncated SVD\n",
    "n_components = 50  # Adjust based on dataset and memory constraints\n",
    "svd = TruncatedSVD(n_components=n_components, random_state=42)\n",
    "user_factors = svd.fit_transform(user_movie_matrix)  # User latent factors\n",
    "movie_factors = svd.components_.T  # Movie latent factors\n",
    "\n",
    "print(\"::::::::::: Movie factors shape => \", movie_factors.shape)\n",
    "print(\"::::::::::: User factors shape => \", user_factors.shape)\n",
    "\n",
    "# Save the user and movie factors for reuse\n",
    "with open(\"../models/user_factors.pkl\", \"wb\") as f:\n",
    "    pickle.dump(user_factors, f)\n",
    "with open(\"../models/movie_factors.pkl\", \"wb\") as f:\n",
    "    pickle.dump(movie_factors, f)\n",
    "\n",
    "# Create a Series to map movie titles to their indices\n",
    "movie_indices = pd.Series(movies.index, index=movies['title']).drop_duplicates()\n",
    "print(\"::::::::::: Movie indices length => \", len(movie_indices))\n",
    "\n",
    "# print(movie_indices.head(10))\n",
    "# Save the movie indices mapping\n",
    "with open('../models/movie_indices.pkl', 'wb') as f:\n",
    "    pickle.dump(movie_indices, f)\n",
    "\n",
    "print(\":::::: PKL files saved !!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "d37345b6-2054-4c4e-a2e6-0dd5d8620348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the Collaborative Recommendation Function\n",
    "def recommend_collaborative(user_id, num_recommendations=5):\n",
    "    \"\"\"\n",
    "    Recommend movies for a user based on collaborative filtering.\n",
    "\n",
    "    Args:\n",
    "        user_id (int): The ID of the user for whom to recommend.\n",
    "        num_recommendations (int): The number of recommendations to return.\n",
    "\n",
    "    Returns:\n",
    "        list: Recommended movie titles.\n",
    "    \"\"\"\n",
    "    # Load user and movie factors\n",
    "    with open(\"../models/user_factors.pkl\", \"rb\") as f:\n",
    "        user_factors = pickle.load(f)\n",
    "    with open(\"../models/movie_factors.pkl\", \"rb\") as f:\n",
    "        movie_factors = pickle.load(f)\n",
    "\n",
    "    # Validate user_id\n",
    "    if user_id is None:\n",
    "        raise ValueError(\"Invalid user_id: user_id cannot be empty\")\n",
    "    if user_id < 1 or user_id > user_factors.shape[0] or user_id is None:\n",
    "        raise ValueError(f\"Invalid user_id: {user_id}. Must be between 1 and {user_factors.shape[0]}.\")\n",
    "\n",
    "    # Retrieve the user's latent factor vector\n",
    "    user_vector = user_factors[user_id - 1]\n",
    "\n",
    "    # Compute similarity scores for all movies\n",
    "    scores = np.dot(movie_factors, user_vector)\n",
    "\n",
    "    # Get indices of the top movie scores\n",
    "    recommended_movie_indices = np.argsort(scores)[::-1][:num_recommendations]\n",
    "\n",
    "    # Map indices to movie titles\n",
    "    recommended_titles = movies.loc[movies.index.isin(recommended_movie_indices), 'title'].tolist()\n",
    "    return recommended_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "919e303e-3fa8-444b-894f-8db52d9b38ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_content_based(title, num_recommendations=10, h5_file='../models/cosine_sim.h5', min_similarity=0.5):\n",
    "    \"\"\"\n",
    "        Adding a min_similarity threshhold dramatically improves this content-based recommendation especially when used\n",
    "        along in a hybrid recommendation system\n",
    "    \"\"\"\n",
    "    \n",
    "    # Normalize the movie title\n",
    "    normalized_title = title.lower().strip()\n",
    "    \n",
    "    # Get the index of the input movie\n",
    "    if normalized_title not in movie_indices:\n",
    "        raise ValueError(f\"Movie '{title}' not found in the dataset.\")\n",
    "    idx = movie_indices[normalized_title]\n",
    "    \n",
    "    # Open the HDF5 file and retrieve the relevant row (cosine similarity scores)\n",
    "    # Instead of loading the entire cosine_sim matrix into memory, retrieve only the relevant row using the index idx.\n",
    "    with h5py.File(h5_file, 'r') as f:\n",
    "        sim_scores = f['cosine_sim'][idx]  # Retrieve the row corresponding to the movie\n",
    "\n",
    "    # Process the similarity scores to get recommendations\n",
    "    sim_scores = list(enumerate(sim_scores))\n",
    "\n",
    "    # Filter by similarity threshold\n",
    "    sim_scores = [(i, score) for i, score in sim_scores if score >= min_similarity]\n",
    "    \n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:num_recommendations+1]  # Skip the movie itself\n",
    "    recommended_indices = [i[0] for i in sim_scores]\n",
    "    \n",
    "    # Retrieve recommended movie titles and convert to title case\n",
    "    recommended_titles = movies['title'].iloc[recommended_indices].str.title()\n",
    "    return recommended_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "5ea4c65c-c22c-4563-b708-129cee49c7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_hybrid(title, user_id=None, content_weight=0.5, collab_weight=0.5, num_recommendations=10, num_content_rec = 100):\n",
    "    \"\"\"\n",
    "    Hybrid recommendation combining content-based and collaborative filtering.\n",
    "    \n",
    "    Args:\n",
    "        title (str): Input movie title for content-based recommendations.\n",
    "        user_id (int): User ID for collaborative filtering recommendations.\n",
    "        content_weight (float): Weight for content-based recommendations.\n",
    "        collab_weight (float): Weight for collaborative filtering recommendations.\n",
    "        num_recommendations (int): Number of recommendations to return.\n",
    "    \n",
    "    Returns:\n",
    "        list: Recommended movie titles.\n",
    "    \"\"\"\n",
    "    # Validate weights\n",
    "    if content_weight + collab_weight != 1.0:\n",
    "        raise ValueError(\"Content weight and collaboration weight must sum to 1.0.\")\n",
    "        \n",
    "    # Content-based recommendations\n",
    "    content_recommendations = recommend_content_based(title, num_recommendations=num_content_rec)\n",
    "\n",
    "    # Collaborative recommendations\n",
    "    if user_id is None:\n",
    "        collaborative_recommendations = []\n",
    "    else:\n",
    "        collaborative_recommendations = recommend_collaborative(user_id, num_recommendations=100)\n",
    "\n",
    "    # Combine scores (assume both return lists of movie titles)\n",
    "    combined_recommendations = (\n",
    "        content_weight * pd.Series(content_recommendations).value_counts(normalize=True) +\n",
    "        collab_weight * pd.Series(collaborative_recommendations).value_counts(normalize=True)\n",
    "    ).sort_values(ascending=False)\n",
    "\n",
    "    # Return top-N recommendations\n",
    "    return combined_recommendations.head(num_recommendations).index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "id": "360733d1-29d4-41ae-9f7b-63c9c09c28ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Toy Story 2 (1999)', 'Toy Story 3 (2010)', 'Toy Story 4 (2019)', 'Toy Story Of Terror (2013)', 'Toy Story That Time Forgot (2014)', 'Toy Story Toons: Hawaiian Vacation (2011)', 'Toy Story Toons: Small Fry (2011)', 'Toy, The (1982)']\n",
      "\n",
      "\n",
      "\n",
      "['Toy Story 2 (1999)', 'Toy Story 3 (2010)', 'Toy Story 4 (2019)', 'Toy Story Of Terror (2013)', 'Toy Story That Time Forgot (2014)', 'Toy Story Toons: Hawaiian Vacation (2011)', 'Toy Story Toons: Small Fry (2011)', 'Toy, The (1982)']\n",
      "\n",
      "\n",
      "\n",
      "['Toy Story 2 (1999)', 'Toy Story 3 (2010)', 'Toy Story 4 (2019)', 'Toy Story Of Terror (2013)', 'Toy Story That Time Forgot (2014)', 'Toy Story Toons: Hawaiian Vacation (2011)', 'Toy Story Toons: Small Fry (2011)', 'Toy, The (1982)', 'across the sea of time (1995)', 'american werewolf in london, an (1981)']\n",
      "\n",
      "\n",
      "\n",
      "['Toy Story 2 (1999)', 'Toy Story 3 (2010)', 'Toy Story 4 (2019)', 'Toy Story Of Terror (2013)', 'Toy Story That Time Forgot (2014)', 'Toy Story Toons: Hawaiian Vacation (2011)', 'Toy Story Toons: Small Fry (2011)', 'Toy, The (1982)', 'amazing panda adventure, the (1995)', 'american president, the (1995)']\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recommendations = recommend_hybrid(\n",
    "    title=\"Toy Story (1995)\",\n",
    "    user_id=None,  # No user ID\n",
    "    content_weight=1.0,\n",
    "    collab_weight=0.0,\n",
    "    num_recommendations=10, \n",
    "    num_content_rec = 100\n",
    ")\n",
    "print(recommendations)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "recommendations = recommend_hybrid(\n",
    "    title=\"Toy Story (1995)\",\n",
    "    user_id=None,  # No user ID\n",
    "    content_weight=0.5,\n",
    "    collab_weight=0.5,\n",
    "    num_recommendations=10, \n",
    "    num_content_rec = 100\n",
    ")\n",
    "print(recommendations)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "recommendations = recommend_hybrid(\n",
    "    title=\"Toy Story (1995)\",\n",
    "    user_id=1,  # No user ID\n",
    "    content_weight=0.5,\n",
    "    collab_weight=0.5,\n",
    "    num_recommendations=10, \n",
    "    num_content_rec = 100\n",
    ")\n",
    "print(recommendations)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "recommendations = recommend_hybrid(\n",
    "    title=\"Toy Story (1995)\",\n",
    "    user_id=2,  # No user ID\n",
    "    content_weight=0.3,\n",
    "    collab_weight=0.7,\n",
    "    num_recommendations=10, \n",
    "    num_content_rec = 100\n",
    ")\n",
    "print(recommendations)\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "id": "f5862e68-ab1b-4c73-a856-770c566f4139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for User 1: ['sudden death (1995)', 'casino (1995)', 'powder (1995)', 'big green, the (1995)', 'eye for an eye (1996)']\n",
      "\n",
      "\n",
      "\n",
      "Recommendations for User 200948: ['boys on the side (1995)', 'man of the house (1995)', 'beverly hills cop iii (1994)', 'inkwell, the (1994)', 'robocop 3 (1993)']\n",
      "\n",
      "\n",
      "\n",
      "Error for User 200948: Invalid user_id: 200949. Must be between 1 and 200948.\n",
      "\n",
      "\n",
      "\n",
      "Expected error for User -1: Invalid user_id: -1. Must be between 1 and 200948.\n"
     ]
    }
   ],
   "source": [
    "# Test recommend_collaborative\n",
    "# Test valid user ID\n",
    "try:\n",
    "    recommendations = recommend_collaborative(user_id=1, num_recommendations=5)\n",
    "    print(f\"Recommendations for User 1: {recommendations}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error for User 1: {e}\")\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "# Test user at upper bound\n",
    "try:\n",
    "    max_user_id = user_factors.shape[0]\n",
    "    recommendations = recommend_collaborative(user_id=max_user_id, num_recommendations=5)\n",
    "    print(f\"Recommendations for User {max_user_id}: {recommendations}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error for User {max_user_id}: {e}\")\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "# Test user beyond upper bound\n",
    "try:\n",
    "    max_user_id = user_factors.shape[0]\n",
    "    recommendations = recommend_collaborative(user_id=max_user_id + 1, num_recommendations=5)\n",
    "    print(f\"Recommendations for User {max_user_id}: {recommendations}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error for User {max_user_id}: {e}\")\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "# Test invalid user ID\n",
    "try:\n",
    "    recommendations = recommend_collaborative(user_id=-1, num_recommendations=5)\n",
    "    print(f\"Recommendations for User -1: {recommendations}\")\n",
    "except Exception as e:\n",
    "    print(f\"Expected error for User -1: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "id": "67770bda-124f-4085-9fb4-4d0e08e940f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Recommendations for 'Toy Story (1995)', User 1: ['Toy Story 2 (1999)', 'Toy Story 3 (2010)', 'Toy Story 4 (2019)', 'Toy Story Of Terror (2013)', 'Toy Story That Time Forgot (2014)']\n",
      "\n",
      "\n",
      "\n",
      "Expected error for 'Nonexistent Movie': Movie 'Nonexistent Movie' not found in the dataset.\n",
      "\n",
      "\n",
      "\n",
      "Expected error for User -1: Invalid user_id: -1. Must be between 1 and 200948.\n",
      "\n",
      "\n",
      "\n",
      ":::::: Test extreme weights - content only ::::::::::\n",
      "Content-Based Only Recommendations: ['Toy Story 2 (1999)', 'Toy Story 3 (2010)', 'Toy Story 4 (2019)', 'Toy Story Of Terror (2013)', 'Toy Story That Time Forgot (2014)']\n",
      "\n",
      ":::::: Test extreme weights - collaborative only ::::::::::\n",
      "Collaborative Only Recommendations: ['Toy Story 2 (1999)', 'Toy Story 3 (2010)', 'Toy Story 4 (2019)', 'Toy Story Of Terror (2013)', 'Toy Story That Time Forgot (2014)']\n",
      "\n",
      "\n",
      "\n",
      "Purely content-based recommendations:\n",
      "['Toy Story 2 (1999)', 'Toy Story 3 (2010)', 'Toy Story 4 (2019)', 'Toy Story Of Terror (2013)', 'Toy Story That Time Forgot (2014)']\n",
      "\n",
      "\n",
      "\n",
      "Recommendations with user_id=None and content focus:\n",
      "['Toy Story 2 (1999)', 'Toy Story 3 (2010)', 'Toy Story 4 (2019)', 'Toy Story Of Terror (2013)', 'Toy Story That Time Forgot (2014)']\n"
     ]
    }
   ],
   "source": [
    "# # Test recommend_hybrid\n",
    "# # Test valid title and user\n",
    "try:\n",
    "    recommendations = recommend_hybrid(\n",
    "        title=\"Toy Story (1995)\",\n",
    "        user_id=1,\n",
    "        content_weight=0.5,\n",
    "        collab_weight=0.5,\n",
    "        num_recommendations=5\n",
    "    )\n",
    "    print(f\"Hybrid Recommendations for 'Toy Story (1995)', User 1: {recommendations}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error for 'Toy Story (1995)', User 1: {e}\")\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "# Test with invalid title\n",
    "try:\n",
    "    recommendations = recommend_hybrid(\n",
    "        title=\"Nonexistent Movie\",\n",
    "        user_id=1,\n",
    "        content_weight=0.5,\n",
    "        collab_weight=0.5,\n",
    "        num_recommendations=5\n",
    "    )\n",
    "    print(f\"Recommendations for 'Nonexistent Movie', User 1: {recommendations}\")\n",
    "except Exception as e:\n",
    "    print(f\"Expected error for 'Nonexistent Movie': {e}\")\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "# Test with invalid user ID\n",
    "try:\n",
    "    recommendations = recommend_hybrid(\n",
    "        title=\"Toy Story (1995)\",\n",
    "        user_id=-1,\n",
    "        content_weight=0.5,\n",
    "        collab_weight=0.5,\n",
    "        num_recommendations=5\n",
    "    )\n",
    "    print(f\"Recommendations for 'Toy Story (1995)', User -1: {recommendations}\")\n",
    "except Exception as e:\n",
    "    print(f\"Expected error for User -1: {e}\")\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "# Test extreme weights\n",
    "\n",
    "try:\n",
    "    print(\":::::: Test extreme weights - content only ::::::::::\")\n",
    "    content_only = recommend_hybrid(\n",
    "        title=\"Toy Story (1995)\",\n",
    "        user_id=1,\n",
    "        content_weight=1.0,\n",
    "        collab_weight=0.0,\n",
    "        num_recommendations=5\n",
    "    )\n",
    "    print(f\"Content-Based Only Recommendations: {content_only}\")\n",
    "\n",
    "    print(\"\\n:::::: Test extreme weights - collaborative only ::::::::::\")\n",
    "    collaborative_only = recommend_hybrid(\n",
    "        title=\"Toy Story (1995)\",\n",
    "        user_id=1,\n",
    "        content_weight=0.0,\n",
    "        collab_weight=1.0,\n",
    "        num_recommendations=5\n",
    "    )\n",
    "    print(f\"Collaborative Only Recommendations: {collaborative_only}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during weight testing: {e}\")\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "# Purely content-based recommendations\n",
    "print(\"Purely content-based recommendations:\")\n",
    "try:\n",
    "    recommendations = recommend_hybrid(\n",
    "        title=\"Toy Story (1995)\",\n",
    "        user_id=None,  # No user ID\n",
    "        content_weight=1.0,\n",
    "        collab_weight=0.0,\n",
    "        num_recommendations=5\n",
    "    )\n",
    "    print(recommendations)\n",
    "except Exception as e:\n",
    "    print(f\"Error during purely content-based testing: {e}\")\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "# Hybrid recommendation with only content-based weight(Hybrid with user_id=None and Custom Weights)\n",
    "print(\"Recommendations with user_id=None and content focus:\")\n",
    "# try:\n",
    "recommendations = recommend_hybrid(\n",
    "    title=\"Toy Story (1995)\",\n",
    "    user_id=None,\n",
    "    content_weight=0.7,  # Adjust weights as needed\n",
    "    collab_weight=0.3,  # Collaborative filtering weight (ignored due to user_id=None)\n",
    "    num_recommendations=5\n",
    ")\n",
    "print(recommendations)\n",
    "# except Exception as e:\n",
    "    # print(f\"Error during recommendations with user_id=None and content focus testing: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5baa0d32-d502-4ee5-a7d4-fc077a995a0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
